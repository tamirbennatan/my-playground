---
title: "Mercari Price Suggestion- Model Building"
output:
  html_document:
    messages: no
    toc: true
    toc_depth: 4
    df_print: paged
    fig_height: 6
    fig_width: 8
---

## 0. Introduction

Here I build my first model for the Mercari Price Suggestion Challenge. 

I posted [an extensive exploratory analysis](https://www.kaggle.com/timib1203/one-honking-data-exploration-mercari-prices) - where I uncovered the structure that motivate the features engineered in this notebook. If you want to learn more about the data, that notebook will be more useful than this one. Please check it out, and leave feedback!

To ensure that I process the training and test data identically, whenever I make a change to the training data, I'll create a function which applies said transformations. This way I can also apply the identical transformations to the test set.

```{R}
start_time <- Sys.time()
```

```{R}
# data handling and manipulations
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(tidyr)))
suppressMessages(suppressWarnings(library(reshape2)))
# string parsing and Regular Expressions
suppressMessages(suppressWarnings(library(stringr)))
# tidy tokenizing
suppressMessages(suppressWarnings(library(tidytext)))
# visualizations
suppressMessages(suppressWarnings(library(ggplot2)))


library(dummies)
```


## 1. Data loading and normalization

#### 1.1 Load data

```{R}
train <- read.csv("data/train.tsv", row.names = NULL, sep = "\t")
# keep track of original columns, in order to revert to loading columns
ORIGINAL.COLUMNS = colnames(train)
# sample to play around with 
set.seed(1)
tmp = sample_n(train, 100)
```

```{R}
# return to orignal columns 
train = train[ORIGINAL.COLUMNS]
```
#### 1.2 Normalize data

There are a few things that I want to fix in the data before starting to build the design matrix. 


```{R}
# function to apply preliminary cleaning tranformations
normalize.data <- function(data){
      # convert the types of factors to characters
      data$name <- as.character(data$name)
      data$brand_name <- as.character(data$brand_name)
      data$item_description <- as.character(data$item_description)
      data$category_name <- as.character(data$category_name) 
      
      # convert the empty string to naive NA values
      data <- data %>% 
      mutate(name = ifelse(name == "", NA, name),
             brand_name = ifelse(brand_name == "", NA, brand_name), 
             item_description = ifelse(item_description == "", NA, item_description), 
             category_name = ifelse(category_name == "", NA, category_name))
      
      # lowercase brand and item description values
      data <- data %>%
            mutate(brand_name = str_to_lower(brand_name), 
                   item_description = str_to_lower(item_description))
      
      # fill item descriptions of `no item description` to NA
      data <- data %>%
            mutate(item_description = ifelse(item_description == "no description yet", NA, item_description))
      
      return (data)
}
```

Now, when we apply the function on our training set, the types of its columns will change appropriately. 

```{R}
# types/values before transform
str(train)
```


```{R}
# train <- train[ORIGINAL.COLUMNS]

# apply transform
train <- normalize.data(train)

# types/values after transform
# str(train)
```



## 1. Building the design matrix. 

Here, I start to build the features described in my exploratory notebook. 

#### 1.1 Category

A function to split the category into three categories (high-level, mid-level, low-level)
```{R}
split.category <- function(data){
      # split the category into a hierarchy
      data <- data %>%
            mutate(category_name = str_to_lower(category_name)) %>%
            separate(col = category_name, 
                     into = c("high_category", "mid_category", "low_category"), 
                     sep = "/", 
                     remove = FALSE) %>%
            unite(mid.low.categories, mid_category, low_category, sep = "|", remove = FALSE)
      return(data)
}
```


```{R}
train <- split.category(train)
```

```{R}
# head(train)
```



Now, a function for converting the high category into one-hot encodings

First get the levels for the categories
```{R}
high.category.levels <- train %>%
      count(high_category) %>% 
      .$high_category 
```

```{R}
category.onehot <- function(data){
      # first, fill any categories that aren't one of the factors to NA
      data <- data %>%
            mutate(high_category = ifelse(high_category %in% high.category.levels, high_category, NA))
      
      # Now, encode as a factor 
      data$high_category <- factor(data$high_category, levels = high.category.levels)
      

      # finally, encode one-hot
      data <- dummy.data.frame(data, names = c("high_category"))
      
      return(data)
}

```

```{R}
train <- category.onehot(train)
```

```{R}
# head(train)
```


Now, to encode the low and mid-level categories:


The 100 first combinations of low/mid categories account for around 75% of the data:

```{R}
low.mid.category.levels = train %>%
      count(mid.low.categories, sort = TRUE) %>%
      top_n(99) %>%
      .$mid.low.categories %>%
      c(., "other")
```

And a function for converting the low.mid categories to one-hot encodings:

```{R}
low.mid.categories.onehot <- function(data){
      # convert any categories not in levels to "other"
      data <- data %>%
            mutate(mid.low.categories = ifelse(mid.low.categories %in% low.mid.category.levels, mid.low.categories, "other"))
      
      # change to a factor
      data$mid.low.categories <- factor(data$mid.low.categories, levels = low.mid.category.levels)
      
      # convert to one-hot encoding
      data <- dummy.data.frame(data, names = c("mid.low.categories"))
      
      return(data)
}
```

```{R}
train <- low.mid.categories.onehot(train)
```

```{R}
# head(train)
```

#### 1.2 Brand name

Here, I'll keep the 70 most frequenlty occuring brands, and one for all else

```{R}
brand.levels <- train %>%
      mutate(brand_name = case_when(
            brand_name == "air jordan" ~ "jordan",
            brand_name == "beats by dr. dre" ~ "beats", 
            TRUE ~ brand_name)
      ) %>%
      count(brand_name, sort = TRUE) %>%
      top_n(70) %>%
      .$brand_name %>%
      c(., "other")
```


A function for converting brand to one-hot vectors

```{R}
brand.onehot <- function(data){
      # convert brands to "other" if they're not in the labels
      data <- data %>% 
            mutate(brand_name = case_when(
                  brand_name == "air Jordan" ~ "jordan",
                  brand_name == "beats by dr. dre" ~ "beats", 
                  TRUE ~ brand_name)
            ) %>%
            mutate(brand_name = ifelse(brand_name %in% brand.levels, brand_name, "other"))
      
      # add a column for whether or not the brand is NA
      data <- data %>%
            mutate(missing.brand = is.na(brand_name))
      
      # convert to a factor 
      data$brand_name <- factor(data$brand_name, levels = brand.levels)
      
      
      tmpcol = data$brand_name
      
      # encode as onehot
      data <- dummy.data.frame(data, names = c("brand_name"))
      
      data$brand_name = tmpcol
      
      return(data)
}
```


```{R}
train <- brand.onehot(train)
```


```{R}
# head(train)
```


#### 1.3 Item condition

The levels here are 1,2,3,4,5. I'll add an extra one, just in case the test set has NA condition. 

```{R}
condition.levels = c(1,2,3,4,5,NA)
```

And a function for encding the item condition

```{R}
condition.onehot <- function(data){
      # if the condition is not in one of the levels, cast it to NA
      data <- data %>%
            mutate(item_condition_id = ifelse(item_condition_id %in% condition.levels, item_condition_id, NA))
      
      # convert to factor
      data$item_condition_id <- factor(data$item_condition_id, levels = condition.levels)
      
      # encode onehot
      data <- dummy.data.frame(data, c("item_condition_id"))
      
      return(data)
}
```

```{R}
train <- condition.onehot(train)
```

```{R}
# head(train)
```

#### 1.4 Shipping

A binary variable that encodes if there's shipping

```{R}
shipping.binary.var <- function(data){
      # fill values with 0 
      data <- data %>%
            replace_na(list(shipping = 0))
      
      # convert to a factor
      data$shipping <- as.factor(data$shipping)
      
      return(data)
}
```


```{R}
train <- shipping.binary.var(train)
```

```{R}
# head(train,100)
```


#### 1.5 Item description

- is missing
- title contains brand
- description contains [rm]

```{R}
basic.text.features <- function(data){
      data <- data %>%
            mutate(description.missing = is.na(item_description), 
                   title.contains.brand = str_detect(name, as.character(brand_name)), 
                   description.contains.rm = str_detect(item_description, fixed("[rm]"))) %>%
            replace_na(list(title.contains.brand = FALSE, description.contains.rm = FALSE))
      
      return(data)
            
}
```



```{R}
train <- basic.text.features(train) 
```

```{R}
# head(train)
```


#### 1.6 Bin specific words

```{R}
tmp = train %>%
      mutate(price.bin = ntile(price, n = 10))  %>%
      group_by(price.bin) %>%
      sample_n(20000) %>%
      ungroup() %>%
      unnest_tokens(word, item_description) %>%
      anti_join(stop_words)

binned.averages = tmp %>%
      mutate(num.postings =  n_distinct(train_id)) %>%
      group_by(word) %>%
      summarize(num.postings = first(num.postings),
                posts.with.word = n_distinct(train_id)) %>%
      mutate(avg.posts.contain.word = posts.with.word/num.postings) %>%
      ungroup() %>%
      inner_join(
            tmp %>%
                  group_by(price.bin) %>%
                  mutate(num.posts.bin = n_distinct(train_id)) %>%
                  group_by(price.bin, word) %>%
                  summarize(num.posts.bin = first(num.posts.bin), 
                            posts.with.word.bin = n_distinct(train_id)) %>%
                  ungroup() %>%
                  mutate(avg.posts.contain.word.bin = posts.with.word.bin/num.posts.bin) 
                  
      ) %>%
      mutate(inter.average.diff = avg.posts.contain.word.bin - avg.posts.contain.word) %>%
      arrange(desc(abs(inter.average.diff))) %>%
      filter(!is.na(word)) 

variance.words <- binned.averages %>%
      filter(posts.with.word > 2000) %>%
      group_by(price.bin) %>%
      top_n(25, wt = abs(inter.average.diff)) %>%
      ungroup() %>%
      select(word)  %>%
      unique() %>%
      rename(variance.words = word) %>%
      filter(variance.words != "rm") %>%
      .$variance.words
```


```{R}
variance.words.onehot <- function(data){
      for (i in 1:length(variance.words)){
            newcol = paste("varword", i, sep = "")
            data[newcol] = str_detect(data$item_description, variance.words[[i]])
            
            data <- replace_na(data, list(newcol = FALSE))
      }
      return(data)
}
```

```{R}
train <- variance.words.onehot(train)
```

```{R}
# head(train)[,200:260]
```

Now a function to remove the unneeded columns. Note that train_id is kept. 

```{R}
filter.columns <- function(data)
      return(
            select(data, -name, -category_name, -mid_category, 
                        -low_category, -item_description, - brand_name)
      )
```

```{R}
train <- filter.columns(train)
```

```{R}
end_time <- Sys.time()

end_time - start_time
```








































