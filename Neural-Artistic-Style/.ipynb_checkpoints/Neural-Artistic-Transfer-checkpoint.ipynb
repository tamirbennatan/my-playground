{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image dimensions constants. \n",
    "OUT_WIDTH = 800\n",
    "OUT_HEIGHT = 600\n",
    "OUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load VGG model. \n",
    "\n",
    "The first step is to load the VGG convolutional neural network as a native Tensorflow Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VGG_PATH = \"pretrained_models/imagenet-vgg-verydeep-19.mat\"\n",
    "# load the Pre-trained VGG weights\n",
    "vgg = loadmat(VGG_PATH)\n",
    "# isolate the layers - and not the metadata\n",
    "layers = vgg['layers'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `layers` is an array, holding each of the weights for each layer as matrices. The order of the layers can be found [here](https://gist.github.com/ksimonyan/3785162f95cd2d5fee77#file-readme-md). \n",
    "\n",
    "To Load the VGG model as a Tensorflow model, I'll need to be do the following:\n",
    "\n",
    "1. Load the weights for each model\n",
    "2. Construct `tf.nn.conv2d` for each 2D convolutional layer - based on loaded weights\n",
    "3. Apply th `relu` activation to each of these convolutional layers\n",
    "4. Remove the max-pooling layers in the VGG network, and replace them with average-pooling layers\n",
    "5. Omit the fully-connected layers in the VGG model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encapsulate the functions needed to load the VGG model in a class\n",
    "class VGGLoader:\n",
    "    \n",
    "    def __init__(self, vgg_path, out_height, out_width, out_channels):\n",
    "        self.vgg_path = vgg_path\n",
    "        self.out_height = out_height\n",
    "        self.out_width = out_width\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    # load the model as a matrix\n",
    "    # store the pre-trained weights as a class atribute\n",
    "    def _load_layers(self):\n",
    "        # load the VGG model\n",
    "        vgg = loadmat(self.vgg_path)\n",
    "        # return just the pre-trained weights\n",
    "        self.layers =  vgg['layers'][0]\n",
    "    \n",
    "    # Load the weights of a given layer\n",
    "    def _get_weights(self,layer):\n",
    "        # load pre-trained weights and biases\n",
    "        weight = self.layers[layer][0][0][2][0][0]\n",
    "        bias = self.layers[layer][0][0][2][0][1]\n",
    "        return weight, bias\n",
    "    \n",
    "    # create a tensorflow convolutional layer based on the pre-trained weights\n",
    "    def _conv2d(self, prev_layer, layer):\n",
    "    \n",
    "        weight, bias = self._get_weights(layer)\n",
    "        W = tf.constant(weight)\n",
    "        b = tf.constant(np.reshape(bias, (bias.size)))\n",
    "        return tf.nn.conv2d(\n",
    "            prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "    \n",
    "    # apply a relu activation onto a Conv2d Layer\n",
    "    def _relu(self, conv2d_layer):\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "    \n",
    "    # create a convolutional layer on the pretrained weights, then apply an activation\n",
    "    def _conv2d_relu(self, prev_layer, layer):\n",
    "        return self._relu(self._conv2d(prev_layer, layer))\n",
    "\n",
    "    # create an average-pooling layer\n",
    "    def _avgpool(self, prev_layer):\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    \n",
    "    ########################################\n",
    "    # Key method - Load and return the VGG model as a Tensorflow Model\n",
    "    ########################################\n",
    "    def get_model(self):\n",
    "        # Load and save the pre-trained weights\n",
    "        self._load_layers()\n",
    "        \n",
    "        # build up the sequential model\n",
    "        model = {}\n",
    "        model['input']   = tf.Variable(np.zeros((1, self.out_height, self.out_width, \\\n",
    "                                                 self.out_channels)), dtype = 'float32')\n",
    "        model['conv1_1']  = self._conv2d_relu(model['input'], 0)\n",
    "        model['conv1_2']  = self._conv2d_relu(model['conv1_1'], 2)\n",
    "        model['avgpool1'] = self._avgpool(model['conv1_2'])\n",
    "        model['conv2_1']  = self._conv2d_relu(model['avgpool1'], 5)\n",
    "        model['conv2_2']  = self._conv2d_relu(model['conv2_1'], 7)\n",
    "        model['avgpool2'] = self._avgpool(model['conv2_2'])\n",
    "        model['conv3_1']  = self._conv2d_relu(model['avgpool2'], 10)\n",
    "        model['conv3_2']  = self._conv2d_relu(model['conv3_1'], 12)\n",
    "        model['conv3_3']  = self._conv2d_relu(model['conv3_2'], 14)\n",
    "        model['conv3_4']  = self._conv2d_relu(model['conv3_3'], 16)\n",
    "        model['avgpool3'] = self._avgpool(model['conv3_4'])\n",
    "        model['conv4_1']  = self._conv2d_relu(model['avgpool3'], 19)\n",
    "        model['conv4_2']  = self._conv2d_relu(model['conv4_1'], 21)\n",
    "        model['conv4_3']  = self._conv2d_relu(model['conv4_2'], 23)\n",
    "        model['conv4_4']  = self._conv2d_relu(model['conv4_3'], 25)\n",
    "        model['avgpool4'] = self._avgpool(model['conv4_4'])\n",
    "        model['conv5_1']  = self._conv2d_relu(model['avgpool4'], 28)\n",
    "        model['conv5_2']  = self._conv2d_relu(model['conv5_1'], 30)\n",
    "        model['conv5_3']  = self._conv2d_relu(model['conv5_2'], 32)\n",
    "        model['conv5_4']  = self._conv2d_relu(model['conv5_3'], 34)\n",
    "        model['avgpool5'] = self._avgpool(model['conv5_4'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = VGGLoader(out_channels=OUT_CHANNELS, out_height=OUT_HEIGHT, out_width= OUT_WIDTH, vgg_path= VGG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'conv2d_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-e261d5b3a867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-435a2d549c76>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_width\u001b[0m\u001b[0;34m,\u001b[0m                                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_1'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv2d_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_2'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv2d_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avgpool1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_avgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-435a2d549c76>\u001b[0m in \u001b[0;36m_conv2d_relu\u001b[0;34m(self, prev_layer, layer)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# create a convolutional layer on the pretrained weights, then apply an activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_conv2d_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# create an average-pooling layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-435a2d549c76>\u001b[0m in \u001b[0;36m_relu\u001b[0;34m(self, conv)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# apply a relu activation onto a Conv2d Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# create a convolutional layer on the pretrained weights, then apply an activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'conv2d_layer' is not defined"
     ]
    }
   ],
   "source": [
    "model = loader.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_vgg_model(path):\n",
    "    \"\"\"\n",
    "    Returns a model for the purpose of 'painting' the picture.\n",
    "    Takes only the convolution layer weights and wrap using the TensorFlow\n",
    "    Conv2d, Relu and AveragePooling layer. VGG actually uses maxpool but\n",
    "    the paper indicates that using AveragePooling yields better results.\n",
    "    The last few fully connected layers are not used.\n",
    "    Here is the detailed configuration of the VGG model:\n",
    "        0 is conv1_1 (3, 3, 3, 64)\n",
    "        1 is relu\n",
    "        2 is conv1_2 (3, 3, 64, 64)\n",
    "        3 is relu    \n",
    "        4 is maxpool\n",
    "        5 is conv2_1 (3, 3, 64, 128)\n",
    "        6 is relu\n",
    "        7 is conv2_2 (3, 3, 128, 128)\n",
    "        8 is relu\n",
    "        9 is maxpool\n",
    "        10 is conv3_1 (3, 3, 128, 256)\n",
    "        11 is relu\n",
    "        12 is conv3_2 (3, 3, 256, 256)\n",
    "        13 is relu\n",
    "        14 is conv3_3 (3, 3, 256, 256)\n",
    "        15 is relu\n",
    "        16 is conv3_4 (3, 3, 256, 256)\n",
    "        17 is relu\n",
    "        18 is maxpool\n",
    "        19 is conv4_1 (3, 3, 256, 512)\n",
    "        20 is relu\n",
    "        21 is conv4_2 (3, 3, 512, 512)\n",
    "        22 is relu\n",
    "        23 is conv4_3 (3, 3, 512, 512)\n",
    "        24 is relu\n",
    "        25 is conv4_4 (3, 3, 512, 512)\n",
    "        26 is relu\n",
    "        27 is maxpool\n",
    "        28 is conv5_1 (3, 3, 512, 512)\n",
    "        29 is relu\n",
    "        30 is conv5_2 (3, 3, 512, 512)\n",
    "        31 is relu\n",
    "        32 is conv5_3 (3, 3, 512, 512)\n",
    "        33 is relu\n",
    "        34 is conv5_4 (3, 3, 512, 512)\n",
    "        35 is relu\n",
    "        36 is maxpool\n",
    "        37 is fullyconnected (7, 7, 512, 4096)\n",
    "        38 is relu\n",
    "        39 is fullyconnected (1, 1, 4096, 4096)\n",
    "        40 is relu\n",
    "        41 is fullyconnected (1, 1, 4096, 1000)\n",
    "        42 is softmax\n",
    "    \"\"\"\n",
    "    vgg = scipy.io.loadmat(path)\n",
    "\n",
    "    vgg_layers = vgg['layers']\n",
    "    def _weights(layer, expected_layer_name):\n",
    "        \"\"\"\n",
    "        Return the weights and bias from the VGG model for a given layer.\n",
    "        \"\"\"\n",
    "        W = vgg_layers[0][layer][0][0][2][0][0]\n",
    "        b = vgg_layers[0][layer][0][0][2][0][1]\n",
    "        layer_name = vgg_layers[0][layer][0][0][0][0]\n",
    "        #pdb.set_trace()\n",
    "\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b\n",
    "\n",
    "    def _relu(conv2d_layer):\n",
    "        \"\"\"\n",
    "        Return the RELU function wrapped over a TensorFlow layer. Expects a\n",
    "        Conv2d layer input.\n",
    "        \"\"\"\n",
    "        return tf.nn.relu(conv2d_layer)\n",
    "\n",
    "    def _conv2d(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        W, b = _weights(layer, layer_name)\n",
    "        W = tf.constant(W)\n",
    "        b = tf.constant(np.reshape(b, (b.size)))\n",
    "        return tf.nn.conv2d(\n",
    "            prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b\n",
    "\n",
    "    def _conv2d_relu(prev_layer, layer, layer_name):\n",
    "        \"\"\"\n",
    "        Return the Conv2D + RELU layer using the weights, biases from the VGG\n",
    "        model at 'layer'.\n",
    "        \"\"\"\n",
    "        return _relu(_conv2d(prev_layer, layer, layer_name))\n",
    "\n",
    "    def _avgpool(prev_layer):\n",
    "        \"\"\"\n",
    "        Return the AveragePooling layer.\n",
    "        \"\"\"\n",
    "        return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Constructs the graph model.\n",
    "    graph = {}\n",
    "    graph['input']   = tf.Variable(np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)), dtype = 'float32')\n",
    "    graph['conv1_1']  = _conv2d_relu(graph['input'], 0, 'conv1_1')\n",
    "    graph['conv1_2']  = _conv2d_relu(graph['conv1_1'], 2, 'conv1_2')\n",
    "    graph['avgpool1'] = _avgpool(graph['conv1_2'])\n",
    "    graph['conv2_1']  = _conv2d_relu(graph['avgpool1'], 5, 'conv2_1')\n",
    "    graph['conv2_2']  = _conv2d_relu(graph['conv2_1'], 7, 'conv2_2')\n",
    "    graph['avgpool2'] = _avgpool(graph['conv2_2'])\n",
    "    graph['conv3_1']  = _conv2d_relu(graph['avgpool2'], 10, 'conv3_1')\n",
    "    graph['conv3_2']  = _conv2d_relu(graph['conv3_1'], 12, 'conv3_2')\n",
    "    graph['conv3_3']  = _conv2d_relu(graph['conv3_2'], 14, 'conv3_3')\n",
    "    graph['conv3_4']  = _conv2d_relu(graph['conv3_3'], 16, 'conv3_4')\n",
    "    graph['avgpool3'] = _avgpool(graph['conv3_4'])\n",
    "    graph['conv4_1']  = _conv2d_relu(graph['avgpool3'], 19, 'conv4_1')\n",
    "    graph['conv4_2']  = _conv2d_relu(graph['conv4_1'], 21, 'conv4_2')\n",
    "    graph['conv4_3']  = _conv2d_relu(graph['conv4_2'], 23, 'conv4_3')\n",
    "    graph['conv4_4']  = _conv2d_relu(graph['conv4_3'], 25, 'conv4_4')\n",
    "    graph['avgpool4'] = _avgpool(graph['conv4_4'])\n",
    "    graph['conv5_1']  = _conv2d_relu(graph['avgpool4'], 28, 'conv5_1')\n",
    "    graph['conv5_2']  = _conv2d_relu(graph['conv5_1'], 30, 'conv5_2')\n",
    "    graph['conv5_3']  = _conv2d_relu(graph['conv5_2'], 32, 'conv5_3')\n",
    "    graph['conv5_4']  = _conv2d_relu(graph['conv5_3'], 34, 'conv5_4')\n",
    "    graph['avgpool5'] = _avgpool(graph['conv5_4'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avgpool1': <tf.Tensor 'AvgPool:0' shape=(1, 300, 400, 64) dtype=float32>,\n",
       " 'avgpool2': <tf.Tensor 'AvgPool_1:0' shape=(1, 150, 200, 128) dtype=float32>,\n",
       " 'avgpool3': <tf.Tensor 'AvgPool_2:0' shape=(1, 75, 100, 256) dtype=float32>,\n",
       " 'avgpool4': <tf.Tensor 'AvgPool_3:0' shape=(1, 38, 50, 512) dtype=float32>,\n",
       " 'avgpool5': <tf.Tensor 'AvgPool_4:0' shape=(1, 19, 25, 512) dtype=float32>,\n",
       " 'conv1_1': <tf.Tensor 'Relu:0' shape=(1, 600, 800, 64) dtype=float32>,\n",
       " 'conv1_2': <tf.Tensor 'Relu_1:0' shape=(1, 600, 800, 64) dtype=float32>,\n",
       " 'conv2_1': <tf.Tensor 'Relu_2:0' shape=(1, 300, 400, 128) dtype=float32>,\n",
       " 'conv2_2': <tf.Tensor 'Relu_3:0' shape=(1, 300, 400, 128) dtype=float32>,\n",
       " 'conv3_1': <tf.Tensor 'Relu_4:0' shape=(1, 150, 200, 256) dtype=float32>,\n",
       " 'conv3_2': <tf.Tensor 'Relu_5:0' shape=(1, 150, 200, 256) dtype=float32>,\n",
       " 'conv3_3': <tf.Tensor 'Relu_6:0' shape=(1, 150, 200, 256) dtype=float32>,\n",
       " 'conv3_4': <tf.Tensor 'Relu_7:0' shape=(1, 150, 200, 256) dtype=float32>,\n",
       " 'conv4_1': <tf.Tensor 'Relu_8:0' shape=(1, 75, 100, 512) dtype=float32>,\n",
       " 'conv4_2': <tf.Tensor 'Relu_9:0' shape=(1, 75, 100, 512) dtype=float32>,\n",
       " 'conv4_3': <tf.Tensor 'Relu_10:0' shape=(1, 75, 100, 512) dtype=float32>,\n",
       " 'conv4_4': <tf.Tensor 'Relu_11:0' shape=(1, 75, 100, 512) dtype=float32>,\n",
       " 'conv5_1': <tf.Tensor 'Relu_12:0' shape=(1, 38, 50, 512) dtype=float32>,\n",
       " 'conv5_2': <tf.Tensor 'Relu_13:0' shape=(1, 38, 50, 512) dtype=float32>,\n",
       " 'conv5_3': <tf.Tensor 'Relu_14:0' shape=(1, 38, 50, 512) dtype=float32>,\n",
       " 'conv5_4': <tf.Tensor 'Relu_15:0' shape=(1, 38, 50, 512) dtype=float32>,\n",
       " 'input': <tf.Variable 'Variable_15:0' shape=(1, 600, 800, 3) dtype=float32_ref>}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_WIDTH = 800\n",
    "IMAGE_HEIGHT = 600\n",
    "COLOR_CHANNELS = 3\n",
    "load_vgg_model(VGG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'relu1_1'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg['layers'][0][0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_layers[0][layer][0][0][2][0][0]\n",
    "vgg_layers[0][layer][0][0][2][0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
